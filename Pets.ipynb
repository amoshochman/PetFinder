{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, MinMaxScaler, StandardScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.metrics import confusion_matrix, cohen_kappa_score, mean_absolute_error, mean_squared_error, make_scorer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC, NuSVC\n",
    "\n",
    "from itertools import chain\n",
    "from seaborn import heatmap\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SmallCategoriesEraser(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        return\n",
    "        \n",
    "    def fit( self, X, y = None  ):\n",
    "        self.biggest_breeds = list(X.Breed1.value_counts(normalize=True)[X.Breed1.value_counts(normalize=True)>0.1].index)\n",
    "        return self\n",
    "        \n",
    "    def _classify_breed(self, breed):\n",
    "        if breed in self.biggest_breeds:\n",
    "            return breed\n",
    "        return -1\n",
    "        \n",
    "    def transform(self, X , y = None ):\n",
    "        X_copy = X.copy()\n",
    "        X_copy.Breed1 = X_copy.Breed1.apply(self._classify_breed)\n",
    "        return X_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_score(pipeline, types, score = cohen_kappa_score):\n",
    "    pipeline.fit(X_train[X_train.Type.isin(types)], y_train[X_train.Type.isin(types)])\n",
    "    y_pred = pipeline.predict(X_test[X_test.Type.isin(types)])\n",
    "    return round(score(y_pred, y_test[X_test.Type.isin(types)]),3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def try_models(*steps):\n",
    "    models = [\n",
    "        KNeighborsClassifier(),\n",
    "        DecisionTreeClassifier(random_state=1),\n",
    "        RandomForestClassifier(random_state=1),\n",
    "        AdaBoostClassifier(random_state=1),\n",
    "        GradientBoostingClassifier(random_state=1)\n",
    "        ]\n",
    "    for model in models:\n",
    "        print(\"<<<<----------------------------------------------------------------------------->>>>\")\n",
    "        print(type(model))\n",
    "        pipeline = make_pipeline(*steps + (model,))\n",
    "        print(\"Model quadratic weighted kappa score for dogs:\", get_score(pipeline, [1]))\n",
    "        print(\"Model quadratic weighted kappa score for cats:\", get_score(pipeline, [2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pet_id(path):\n",
    "    file_name = ntpath.basename(path)\n",
    "    end = file_name.rfind('.json')\n",
    "    return file_name[:end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "def get_sentiment_df(folder):\n",
    "    df = pd.DataFrame(columns = [\"PetID\", \"SentimentMagnitude\", \"SentimentScore\"])\n",
    "    i=0\n",
    "    pattern = os.path.join(folder, '*.json')\n",
    "    for file_name in glob(pattern):\n",
    "        with open(file_name, encoding=\"utf8\", errors=\"ignore\") as json_file:\n",
    "            data = json.load(json_file)\n",
    "            sentiment = data[\"documentSentiment\"]\n",
    "            df.loc[i] = [get_pet_id(file_name), sentiment[\"magnitude\"], sentiment[\"score\"]]\n",
    "            i+=1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train/train.csv\")\n",
    "test = pd.read_csv(\"test/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_sentiment_df = pd.read_csv(\"train_sentiment.csv\")\n",
    "    test_sentiment_df = pd.read_csv(\"test_sentiment.csv\")\n",
    "except IOError:\n",
    "    train_sentiment_df = get_sentiment_df('train_sentiment')\n",
    "    test_sentiment_df = get_sentiment_df('train_sentiment')\n",
    "    train_sentiment_df.to_csv(\"train_sentiment.csv\", index=False)\n",
    "    test_sentiment_df.to_csv(\"test_sentiment.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.merge(train, train_sentiment_df, how=\"left\")\n",
    "test = pd.merge(test, train_sentiment_df, how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=\"AdoptionSpeed\")\n",
    "y = train.AdoptionSpeed\n",
    "\n",
    "categorical_features = list(X.select_dtypes(\"object\").columns)\n",
    "numerical_features = [col for col in X if col not in categorical_features]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_features_with_categoric_meaning = [\"Breed1\", \"Breed2\", \"Gender\", \"Color1\", \"Color2\", \"Color3\", \"Vaccinated\", \"Dewormed\", \"Sterilized\",\"State\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_transformer = make_column_transformer((SimpleImputer(), [col for col in numerical_features if col not in numerical_features_with_categoric_meaning]),\n",
    "                                              (OneHotEncoder(handle_unknown=\"ignore\"), numerical_features_with_categoric_meaning))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [SmallCategoriesEraser(), column_transformer]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<<<<----------------------------------------------------------------------------->>>>\n",
      "<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
      "Model quadratic weighted kappa score for dogs: 0.156\n",
      "Model quadratic weighted kappa score for cats: 0.084\n",
      "<<<<----------------------------------------------------------------------------->>>>\n",
      "<class 'sklearn.tree._classes.DecisionTreeClassifier'>\n",
      "Model quadratic weighted kappa score for dogs: 0.14\n",
      "Model quadratic weighted kappa score for cats: 0.096\n",
      "<<<<----------------------------------------------------------------------------->>>>\n",
      "<class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
      "Model quadratic weighted kappa score for dogs: 0.237\n",
      "Model quadratic weighted kappa score for cats: 0.152\n",
      "<<<<----------------------------------------------------------------------------->>>>\n",
      "<class 'sklearn.ensemble._weight_boosting.AdaBoostClassifier'>\n",
      "Model quadratic weighted kappa score for dogs: 0.163\n",
      "Model quadratic weighted kappa score for cats: 0.148\n",
      "<<<<----------------------------------------------------------------------------->>>>\n",
      "<class 'sklearn.ensemble._gb.GradientBoostingClassifier'>\n",
      "Model quadratic weighted kappa score for dogs: 0.199\n",
      "Model quadratic weighted kappa score for cats: 0.147\n"
     ]
    }
   ],
   "source": [
    "try_models(*steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the performance for each case is pretty different, among all models. That gives us the intuition that we should not apply the same model for both. Random Forest and GradientBoosting give so far the best results for both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(SmallCategoriesEraser(), column_transformer, RandomForestClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(10, 40, num = 5)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5]\n",
    "min_samples_leaf = [1, 2]\n",
    "bootstrap = [True, False]\n",
    "param_grid = {'randomforestclassifier__n_estimators': n_estimators,\n",
    "               'randomforestclassifier__max_features': max_features,\n",
    "               'randomforestclassifier__max_depth': max_depth,\n",
    "               'randomforestclassifier__min_samples_split': min_samples_split,\n",
    "               'randomforestclassifier__min_samples_leaf': min_samples_leaf,\n",
    "               'randomforestclassifier__bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "kappa_scorer = make_scorer(cohen_kappa_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_random = RandomizedSearchCV(estimator = pipeline, param_distributions = param_grid, n_iter = 5, cv = 3, verbose=2, random_state=42, n_jobs = -1, scoring=kappa_scorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  15 out of  15 | elapsed:  1.2min finished\n"
     ]
    }
   ],
   "source": [
    "search1 = rf_random.fit(X_train[X_train.Type==1], y_train[X_train.Type==1])\n",
    "search2 = rf_random.fit(X_train[X_train.Type==2], y_train[X_train.Type==2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best params are equal between the cases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'randomforestclassifier__n_estimators': 1200,\n",
       "  'randomforestclassifier__min_samples_split': 5,\n",
       "  'randomforestclassifier__min_samples_leaf': 2,\n",
       "  'randomforestclassifier__max_features': 'auto',\n",
       "  'randomforestclassifier__max_depth': None,\n",
       "  'randomforestclassifier__bootstrap': True},\n",
       " {'randomforestclassifier__n_estimators': 1200,\n",
       "  'randomforestclassifier__min_samples_split': 5,\n",
       "  'randomforestclassifier__min_samples_leaf': 2,\n",
       "  'randomforestclassifier__max_features': 'auto',\n",
       "  'randomforestclassifier__max_depth': None,\n",
       "  'randomforestclassifier__bootstrap': True})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search1.best_params_, search2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.196"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_score(search1.best_estimator_, [1,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
